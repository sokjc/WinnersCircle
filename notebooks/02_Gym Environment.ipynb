{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://raw.githubusercontent.com/sokjc/WinnersCircle/master/assets/WinnersCircle-small-icononly.png\" width=200 />\n",
    "## Winner's Circle: RL Workshop\n",
    "\n",
    "# Part 02: Gym Environment\n",
    "For the exercises and workshop materials over the next two days, we will be using the `Gym` packaged developed by the OpenAI team. \n",
    "\n",
    "> Gym is a toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Pinball. - *OpenAI*\n",
    "\n",
    "## Why Gym? \n",
    "\n",
    "* RL is very general encompassing all problems that involve making a sequence of decisions.\n",
    "* RL algorithms have started to achieve good results in many difficult environments.\n",
    "* The need for better benchmarks in RL\n",
    "* Lack of standardization of environments used in publications\n",
    "\n",
    "Let's get started with creating our first environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Plotting\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a breakout environment\n",
    "env = gym.make(\"Breakout-v0\")\n",
    "\n",
    "# Reset it, returns the starting frame\n",
    "frame = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    # You would use this command on your local machine to display window of environment\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    # Perform a random action, returns the new frame, reward and whether the game is over\n",
    "    action = env.action_space.sample()\n",
    "    frame, reward, done, info = env.step(action)\n",
    "    \n",
    "    if done: \n",
    "        frame = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "*10 Minutes*\n",
    "\n",
    "Gyms supports thousands of environments. Unfortunately, our server environment only plays nicely with the Atari games at the moment. Explore the  Gym documentation and create an environment of your favorite Atari game. Feel free to try more than one option! You can find the documentation on the various Gym Atari environments [here](https://gym.openai.com/envs/#atari). My personal favorite is SpaceInvaders. üöÄ\n",
    "\n",
    "* Spend the the time to re-type the code above\n",
    "* Research possible parameters\n",
    "* Break the code üòè "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MarioRL",
   "language": "python",
   "name": "mariorl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
